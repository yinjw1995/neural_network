### 结构化机器学习项目

#### 正交化

- 在机器学习中，为了可以对每个参数的调节都能独立的影响最终的性能引入正交化，即根据不同部分反映的问题，去做相应的调整，从而更加容易地判断出是在哪一个部分出现了问题，并做相应的解决措施。

- 正交化或正交性是一种系统设计属性，其确保修改算法的指令或部分不会对系统的其他部分产生或传播副作用。 相互独立地验证使得算法变得更简单，减少了测试和开发的时间。

  为了方便理解，可以假想为每个影响特征都是对应一个旋钮（knob），比如汽车的速度和转向，如果设计出的knob可以分别单独控制速度和转向，调节一个时另一个不受影响，这就是正交化。如果设计的两个knob彼此关联，则不是

- 因此，在监督学习中，我们可以得到下面四个相互正交的假设，并且，可以通过所训练出的模型对应修改哪一项。

  - 模型是否在训练集上表现良好

    如果表现不好，就寻找**更大的神经网络**和**更好的优化算法**

  - 模型是否在开发集上表现良好

    如果表现不好，就是用**正则化**或者**更大训练集**

  - 模型是否在测试集上表现良好

    如果表现不好，就是用**更大的开发集**

  - 模型是否可以在真实的环境中表现良好

    如果表现不好，则修改**开发集和测试集**、修改**代价函数**

  ​

#### 单一数字评估指标

在训练机器学习模型的时候，无论是调整超参数，还是尝试更好的优化算法，如果设置一个单一数字评估指标，也就是只用一个指标来表明模型的好坏，可以更快的评估模型。

**例1** ：下面有两个分类器，包含precision（查准率），recall（查全率）以及F1 score（F1指标）

![17](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/17.jpg)

可以看出，如果是看两个指标很难准确具体的判断哪个分类器好，通过引入单一数字指标可以很快的得到分类器A更好。

**F1指标介绍** 

在二分类问题中，通过预测我们得到下面的真实值 $y$ 和预测值 $\hat y$ 的表：

![18](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/18.jpg)

- Precision（查准率）：

$Precision = \dfrac{True\ positive}{Number\ of\ predicted\ positive} \times 100\%= \dfrac{True\ positive}{True\ positive + False\ positive}$

假设在是否为猫的分类问题中，查准率代表：所有模型预测为猫的图片中，确实为猫的概率。

- Recall（查全率）：

$Recall = \dfrac{True\ positive}{Number\ of\ actually\ positive} \times 100\%= \dfrac{True\ positive}{True\ positive + False\ negative}$

假设在是否为猫的分类问题中，查全率代表：真实为猫的图片中，预测正确的概率。

- F1 Score：

$F1-Socre = \dfrac {2} {\dfrac{1}{p}+\dfrac{1}{r}}$

相当于查准率和查全率的一个特别形式的平均指标。



**例2** ：分类器在不同的国家中的分类错误率结果如图：

如果单独看每个地区的准确率很难判断到底哪个分类器好，但是，如果将每个地区的准确率进行平均，得到单一指标则很容易看出哪个分类器好。

![19](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/19.jpg)



#### 满足和优化指标

**满足指标：** 表示必须要达到的指标。

**优化指标：** 表示尽可能高，实现优化的指标

假设有三个不同的分类器性能表现如下：

![20](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/20.jpg)

这里，精度为优化指标，运行时间为满足指标

一般的，如果要考虑N个指标，则选择一个指标为优化指标，其他N-1个指标都是满足指标：

$N_{metric}:\left\{ \begin{array}{l} 1\qquad \qquad \qquad Optimizing\ metric\\ N_{metric}-1\qquad Satisificing\ metric \end{array} \right.$ 



#### 训练、开发、测试集

训练、开发、测试集选择设置的一些规则和意见：

- 训练、开发、测试集的设置会对产品带来非常大的影响；
- 在选择**开发集**和**测试集**时要使二者来自同一分布，且从**所有数据中随机选取**；（*不同分布分数据，相当于不同的靶心*）
- 所选择的开发集和测试集中的数据，要与未来想要或者能够得到的数据类似，即模型数据和未来数据要具有**相似性**；
- 设置的测试集只要足够大，使其能够在过拟合的系统中给出高方差的结果就可以，也许10000左右的数目足够；
- 设置开发集只要足够使其能够检测不同算法、不同模型之间的优劣差异就可以，百万大数据中 $1\%$ 的大小就足够；



#### 改变开发、测试集和评估指标

在针对某一问题我们设置开发集和评估指标后，这就像把目标定在某个位置，后面的过程就聚焦在该位置上。但有时候在这个项目的过程中，可能会发现目标的位置设置错了，所以要移动改变我们的目标。

**例1：** 

假设有两个猫的图片的分类器：

- 评估指标（metric）：分类错误率（classification error）
- algorithm A：3% error
- algorithm B：5% error

这样来看，算法A的表现更好。但是在实际的测试中，算法A可能因为某些原因，将很多色情图片分类成了猫。所以当我们在线上部署的时候，算法A会给爱猫人士推送更多更准确的猫的图片（因为其误差率只有 $3\%$ ），但同时也会给用户推送一些色情图片，这是不能忍受的。所以，虽然算法A的错误率很低，但是它却不是一个好的算法。

这个时候我们就需要改变开发集、测试集或者评估指标。

假设开始我们的评估指标如下：

$Error = \dfrac{1}{m_{dev}}\sum\limits_{i=1}^{m_{dev}}I\{y^{(i)}_{pred}\neq y^{(i)}\}$

该评估指标对色情图片和非色情图片一视同仁，但是我们希望，分类器不会错误将色情图片标记为猫。

修改的方法，在其中加入权重 $w^{(i)}$ ：

$Error = \dfrac{1}{\sum w^{(i)}}\sum\limits_{i=1}^{m_{dev}} w^{(i)}I\{y^{(i)}_{pred}\neq y^{(i)}\}$

其中：

$w^{(i)}=\left\{ \begin{array}{l} 1\ \ \ \qquad \qquad \qquad 如果x^{(i)}不是色情图片\\ 10或100\qquad \qquad如果x^{(i)}是色情图片 \end{array} \right.$

这样通过设置权重，当算法将色情图片分类为猫时，误差项会快速变大。

总结来说就是：如果评估指标无法正确评估算法的排名，则需要重新定义一个新的评估指标。

**例2：** 

这里有两个猫分类器：

![21](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/21.jpg)

由训练误差可以看出分类器A的分类效果比较好。但实际情况是对分类器A，我们一直使用的是网上下载的高质量的图片进行训练；而当部署到手机上时，由于图片的清晰度及拍照水平的原因，当实际测试算法时，会发现算法B的表现其实更好。因此，需要更改开发集，让你的数据更好的能反映实际数据

总结：如果在训练开发测试的过程中得到的模型效果比较好，但是在实际应用中自己所真正关心的问题效果却不好的时候，就需要改变开发、测试集或者评估指标。