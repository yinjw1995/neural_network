### 结构化机器学习项目

#### 正交化

- 在机器学习中，为了可以对每个参数的调节都能独立的影响最终的性能引入正交化，即根据不同部分反映的问题，去做相应的调整，从而更加容易地判断出是在哪一个部分出现了问题，并做相应的解决措施。

- 正交化或正交性是一种系统设计属性，其确保修改算法的指令或部分不会对系统的其他部分产生或传播副作用。 相互独立地验证使得算法变得更简单，减少了测试和开发的时间。

  为了方便理解，可以假想为每个影响特征都是对应一个旋钮（knob），比如汽车的速度和转向，如果设计出的knob可以分别单独控制速度和转向，调节一个时另一个不受影响，这就是正交化。如果设计的两个knob彼此关联，则不是

- 因此，在监督学习中，我们可以得到下面四个相互正交的假设，并且，可以通过所训练出的模型对应修改哪一项。

  - 模型是否在训练集上表现良好

    如果表现不好，就寻找**更大的神经网络**和**更好的优化算法**

  - 模型是否在开发集上表现良好

    如果表现不好，就是用**正则化**或者**更大训练集**

  - 模型是否在测试集上表现良好

    如果表现不好，就是用**更大的开发集**

  - 模型是否可以在真实的环境中表现良好

    如果表现不好，则修改**开发集和测试集**、修改**代价函数**

  ​

#### 单一数字评估指标

在训练机器学习模型的时候，无论是调整超参数，还是尝试更好的优化算法，如果设置一个单一数字评估指标，也就是只用一个指标来表明模型的好坏，可以更快的评估模型。

**例1** ：下面有两个分类器，包含precision（查准率），recall（查全率）以及F1 score（F1指标）

![17](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/17.jpg)

可以看出，如果是看两个指标很难准确具体的判断哪个分类器好，通过引入单一数字指标可以很快的得到分类器A更好。

**F1指标介绍** 

在二分类问题中，通过预测我们得到下面的真实值 $y$ 和预测值 $\hat y$ 的表：

![18](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/18.jpg)

- Precision（查准率）：

$Precision = \dfrac{True\ positive}{Number\ of\ predicted\ positive} \times 100\%= \dfrac{True\ positive}{True\ positive + False\ positive}$

假设在是否为猫的分类问题中，查准率代表：所有模型预测为猫的图片中，确实为猫的概率。

- Recall（查全率）：

$Recall = \dfrac{True\ positive}{Number\ of\ actually\ positive} \times 100\%= \dfrac{True\ positive}{True\ positive + False\ negative}$

假设在是否为猫的分类问题中，查全率代表：真实为猫的图片中，预测正确的概率。

- F1 Score：

$F1-Socre = \dfrac {2} {\dfrac{1}{p}+\dfrac{1}{r}}$

相当于查准率和查全率的一个特别形式的平均指标。



**例2** ：分类器在不同的国家中的分类错误率结果如图：

如果单独看每个地区的准确率很难判断到底哪个分类器好，但是，如果将每个地区的准确率进行平均，得到单一指标则很容易看出哪个分类器好。

![19](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/19.jpg)



#### 满足和优化指标

**满足指标：** 表示必须要达到的指标。

**优化指标：** 表示尽可能高，实现优化的指标

假设有三个不同的分类器性能表现如下：

![20](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/20.jpg)

这里，精度为优化指标，运行时间为满足指标

一般的，如果要考虑N个指标，则选择一个指标为优化指标，其他N-1个指标都是满足指标：

$N_{metric}:\left\{ \begin{array}{l} 1\qquad \qquad \qquad Optimizing\ metric\\ N_{metric}-1\qquad Satisificing\ metric \end{array} \right.$ 



#### 训练、开发、测试集

训练、开发、测试集选择设置的一些规则和意见：

- 训练、开发、测试集的设置会对产品带来非常大的影响；
- 在选择**开发集**和**测试集**时要使二者来自同一分布，且从**所有数据中随机选取**；（*不同分布分数据，相当于不同的靶心*）
- 所选择的开发集和测试集中的数据，要与未来想要或者能够得到的数据类似，即模型数据和未来数据要具有**相似性**；
- 设置的测试集只要足够大，使其能够在过拟合的系统中给出高方差的结果就可以，也许10000左右的数目足够；
- 设置开发集只要足够使其能够检测不同算法、不同模型之间的优劣差异就可以，百万大数据中 $1\%$ 的大小就足够；



#### 改变开发、测试集和评估指标

在针对某一问题我们设置开发集和评估指标后，这就像把目标定在某个位置，后面的过程就聚焦在该位置上。但有时候在这个项目的过程中，可能会发现目标的位置设置错了，所以要移动改变我们的目标。

**例1：** 

假设有两个猫的图片的分类器：

- 评估指标（metric）：分类错误率（classification error）
- algorithm A：3% error
- algorithm B：5% error

这样来看，算法A的表现更好。但是在实际的测试中，算法A可能因为某些原因，将很多色情图片分类成了猫。所以当我们在线上部署的时候，算法A会给爱猫人士推送更多更准确的猫的图片（因为其误差率只有 $3\%$ ），但同时也会给用户推送一些色情图片，这是不能忍受的。所以，虽然算法A的错误率很低，但是它却不是一个好的算法。

这个时候我们就需要改变开发集、测试集或者评估指标。

假设开始我们的评估指标如下：

$Error = \dfrac{1}{m_{dev}}\sum\limits_{i=1}^{m_{dev}}I\{y^{(i)}_{pred}\neq y^{(i)}\}$

该评估指标对色情图片和非色情图片一视同仁，但是我们希望，分类器不会错误将色情图片标记为猫。

修改的方法，在其中加入权重 $w^{(i)}$ ：

$Error = \dfrac{1}{\sum w^{(i)}}\sum\limits_{i=1}^{m_{dev}} w^{(i)}I\{y^{(i)}_{pred}\neq y^{(i)}\}$

其中：

$w^{(i)}=\left\{ \begin{array}{l} 1\ \ \ \qquad \qquad \qquad 如果x^{(i)}不是色情图片\\ 10或100\qquad \qquad如果x^{(i)}是色情图片 \end{array} \right.$

这样通过设置权重，当算法将色情图片分类为猫时，误差项会快速变大。

总结来说就是：如果评估指标无法正确评估算法的排名，则需要重新定义一个新的评估指标。

**例2：** 

这里有两个猫分类器：

![21](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/21.jpg)

由训练误差可以看出分类器A的分类效果比较好。但实际情况是对分类器A，我们一直使用的是网上下载的高质量的图片进行训练；而当部署到手机上时，由于图片的清晰度及拍照水平的原因，当实际测试算法时，会发现算法B的表现其实更好。因此，需要更改开发集，让你的数据更好的能反映实际数据

总结：如果在训练开发测试的过程中得到的模型效果比较好，但是在实际应用中自己所真正关心的问题效果却不好的时候，就需要改变开发、测试集或者评估指标。



#### 为什么对比人的标准

- 模型的预测能力在很多领域都很接近甚至超越了人类标准
- 人类的预测流程可以帮助模型改进预测能力，使其更加接近人类水平
- 在低于人类水平时，可以使用下面方法进行模型优化
  - 人类帮助标识数据喂给学习算法，增加数据
  - 只要人类可以做的更好，则可以让人去看看算法处理的例子，知道哪里出错了，并尝试去分析为什么人可以作对，而算法不行
  - 也可以更好的分析偏差和方差
- 一旦机器学习算法超过了人类，上面三个策略就没法使用了，并且，可以改进的空间很小了
  - 原因1,：人类的标准已经很高了，或者接近极限优化标准
  - 原因2：在人类标准以下时，人类总是可以寻找到一定的解决办法去改进模型，给模型更多的数据去训练。一旦超越了人类，人类自身都无法做对，上面三个改进方法就不在适用了。



#### 避免误差

对于训练出来的模型，如果知道了训练误差和方差，如何确定先优化误差还是先优化方差呢

![22](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/22.jpg)

对于左边的问题，人类的误差为 ![1\%](http://www.zhihu.com/equation?tex=1%5C%25) ，对于右边的问题，人类的误差为 ![7.5\%](http://www.zhihu.com/equation?tex=7.5%5C%25) 。

对于某些任务如计算机视觉上，人类能够做到的水平和**贝叶斯误差**相差不远。（这里贝叶斯误差指最好的分类器的分类误差，也就是说没有分类器可以做到 $100\%$正确）。这里将人类水平误差近似为贝叶斯误差。

- 左边的例子： $8\%$ 与  $1\%$差距较大

主要着手**减少偏差**，即减少训练集误差和人类水平误差之间的差距，来提高模型性能。

- 右边的例子: $8\%$与  $7.5\%$接近

主要着手**减少方差**，即减少开发集误差和测试集误差之间的差距，来提高模型性能

**总结：**

对人类水平误差有一个大概的估计，可以让我们去估计贝叶斯误差，这样可以让我们更快的做出决定：**减少偏差**还是**减少方差**。

而这个决策技巧通常都很有效果，直到系统的性能开始超越人类，那么我们对贝叶斯误差的估计就不再准确了，再从减少偏差和减少方差方面提升系统性能就会比较困难了。

![23](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/23.jpg)

#### 改善模型的表现

**基本假设：**

- 模型在训练集上有很好的表现；
- 模型推广到开发和测试集也会给你也有很好的表现。

**减少可避免偏差**

- 训练更大的模型
- 训练更长时间、训练更好的优化算法（Momentum、RMSprop、Adam）
- 寻找更好的网络架构（RNN、CNN）、寻找更好的超参数

**减少方差**

- 收集更多的数据
- 正则化（L2、dropout、数据增强）
- 寻找更好的网络架构（RNN、CNN）、寻找更好的超参数

![24](https://raw.githubusercontent.com/yinjw1995/neural_network/master/note_pictures/24.jpg)